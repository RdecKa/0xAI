import sys
import getopt
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

from sklearn.tree import DecisionTreeRegressor
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split

import decision_tree as dt
import linear_regression as lr


def write_sample_file(outfolder, feature_names):
    with open(outfolder + "sample.go", "w") as sample_file:
        sample_file.write("// Package ab (Code generated by a Python script)\n")
        sample_file.write("package ab\n\n")
        sample_file.write("type Sample struct {\n\t")
        sample_file.write(feature_names[0])
        for f in feature_names[1:]:
            sample_file.write(", " + f)
        sample_file.write(" int\n")
        sample_file.write("}")


def main(argv):
    # Read flags
    datafile = "sample_data/data.in"
    outfolder = "sample_out/"
    try:
        opts, args = getopt.getopt(argv, "d:o:")
    except getopt.GetoptError:
        print("Error parsing the command line arguments")
        sys.exit(1)
    for o, a in opts:
        if o == "-d":
            datafile = a
        if o == "-o":
            outfolder = a

    # Read data from file
    print("Reading data from file:", datafile)
    df = pd.read_csv(datafile, comment="#",
                     dtype={"value": np.float64, "num_stones": np.uint8,
                            "occ_red_rows": np.uint8, "occ_red_cols": np.uint8,
                            "occ_blue_rows": np.uint8, "occ_blue_cols": np.uint8,
                            "red_p0": np.uint8, "blue_p0": np.uint8,
                            "red_p1": np.uint8, "blue_p1": np.uint8,
                            "red_p2": np.uint8, "blue_p2": np.uint8,
                            "red_p3": np.uint8, "blue_p3": np.uint8,
                            "red_p4": np.uint8, "blue_p4": np.uint8,
                            "lp": bool,
                            "dtc": np.uint8})

    y = df["value"]
    X = df.drop(columns=["value"])

    feature_names = X.columns
    write_sample_file(outfolder, feature_names)

    # Split
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1,
                                                        random_state=4224)

    # Create decision tree models
    dt_models = [
        DecisionTreeRegressor(max_depth=5, min_samples_leaf=5),
        DecisionTreeRegressor(max_depth=10, min_samples_leaf=5),
        DecisionTreeRegressor(max_depth=None, min_samples_leaf=1),
        DecisionTreeRegressor(max_depth=None, min_samples_leaf=10),
        DecisionTreeRegressor(max_depth=None, min_samples_leaf=20),
        DecisionTreeRegressor(max_depth=None, min_samples_leaf=50),
    ]

    # Create linear regression models
    lr_models = [
        LinearRegression(normalize=True, n_jobs=-1)
    ]

    learners = [
        dt.DecisionTreeLearner(dt_models, feature_names),
        lr.LinearRegressionLearner(lr_models, feature_names),
    ]

    # Create a plot
    plt.figure(figsize=(10, 6))
    plt.plot(y_test.tolist(), label="actual values", linewidth=0.7)
    plt.ylim(-1.2, 1.2)

    for learner in learners:
        # Create file for statistics
        with open(outfolder + "stats_" + learner.short_name() + ".txt", "w") \
                as stats_file:
            models = learner.get_models()
            for model_index in range(len(models)):
                model = models[model_index]

                # Train
                model.fit(X_train, y_train)

                # Predict
                y1 = model.predict(X_test)

                # Print statistics
                stats_file.write("##########################################\n")
                stats_file.write("Statistics for:" + str(model) + "\n")

                feature_importances = model.feature_importances()
                if isinstance(learner, dt.DecisionTreeLearner):
                    stats_file.write("Feature importances:\n")
                else:
                    stats_file.write("Feature coefficients:\n")
                s = ""
                for (n, v) in zip(feature_names, feature_importances):
                    s += "\t" + n + ": " + str(v) + "\n"
                stats_file.write(s)

                sc = model.score(X_test, y_test)
                stats_file.write("SCORE: " + str(sc) + "\n")

                # Output some custom properties for current model
                model.custom_output(model_index, outfolder)

                # Create a plot for feature importances
                plt.figure(num=str(model))
                plt.bar(feature_names, feature_importances)
                plt.gcf().subplots_adjust(bottom=0.35)
                plt.xticks(rotation='vertical')
                plt.savefig(outfolder + "features_" + model.get_ID() + ".pdf")
                plt.close()

                # Add results to plot of all models
                plt.plot(y1, label="predicted values - " + model.name(),
                         linewidth=0.7)

    plt.xlabel("Samples")
    plt.ylabel("Value")
    plt.title("Comparison of predicted and actual values")
    plt.legend(fontsize="x-small")
    plt.savefig(outfolder + "plot_predictions.pdf")
    plt.close()


if __name__ == "__main__":
    main(sys.argv[1:])
